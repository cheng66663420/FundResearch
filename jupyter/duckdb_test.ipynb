{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import contextlib\n",
    "import duckdb\n",
    "def duckdb_query(query):\n",
    "    query = query.replace('\"', \"'\")\n",
    "    PARAMETERS = 'host=192.20.57.208 user=chen7 port=3306 database=chentiancheng password=1991727asdf'\n",
    "    ATTACH_QUERY = f\"ATTACH '{PARAMETERS}' AS mysqldb (TYPE MYSQL);\"\n",
    "    USE_QUERY = \"USE mysqldb;\"\n",
    "    with duckdb.connect() as con:\n",
    "        con.sql(ATTACH_QUERY)\n",
    "        # con.sql(USE_QUERY)\n",
    "        # df = con.sql(query).df()\n",
    "        df = con.sql(\n",
    "            f\"\"\"SELECT * FROM mysql_query(\"mysqldb\", \"{query}\")\"\"\"\n",
    "        ).df()\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.columns:\n",
    "        with contextlib.suppress(Exception):\n",
    "            df_copy[col] = df_copy[col].str.decode(\"utf-8\")\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER_SYMBOL</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>ADJ_NAV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>6.563172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>6.530872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>6.601930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>6.589011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>6.511493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>163415</td>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>6.114847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>163415</td>\n",
       "      <td>2024-11-12</td>\n",
       "      <td>6.101082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>163415</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>6.130332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>163415</td>\n",
       "      <td>2024-11-14</td>\n",
       "      <td>5.970320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>163415</td>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>5.865366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TICKER_SYMBOL   END_DATE   ADJ_NAV\n",
       "0          000001 2023-01-03  6.563172\n",
       "1          000001 2023-01-04  6.530872\n",
       "2          000001 2023-01-05  6.601930\n",
       "3          000001 2023-01-06  6.589011\n",
       "4          000001 2023-01-09  6.511493\n",
       "..            ...        ...       ...\n",
       "907        163415 2024-11-11  6.114847\n",
       "908        163415 2024-11-12  6.101082\n",
       "909        163415 2024-11-13  6.130332\n",
       "910        163415 2024-11-14  5.970320\n",
       "911        163415 2024-11-15  5.865366\n",
       "\n",
       "[912 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sql = \"\"\"\n",
    "select \n",
    "    TICKER_SYMBOL,\n",
    "    END_DATE, \n",
    "    ADJ_NAV\n",
    "from \n",
    "    fund_adj_nav\n",
    "where \n",
    "    1=1\n",
    "    and END_DATE between '2023-01-01' and '20241115'\n",
    "    and TICKER_SYMBOL in ('000001', '163415')\n",
    "\"\"\"\n",
    "df = duckdb_query(query_sql)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (912, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>TICKER_SYMBOL</th><th>END_DATE</th><th>ADJ_NAV</th></tr><tr><td>str</td><td>datetime[μs]</td><td>f64</td></tr></thead><tbody><tr><td>&quot;000001&quot;</td><td>2023-01-03 00:00:00</td><td>6.563172</td></tr><tr><td>&quot;000001&quot;</td><td>2023-01-04 00:00:00</td><td>6.530872</td></tr><tr><td>&quot;000001&quot;</td><td>2023-01-05 00:00:00</td><td>6.60193</td></tr><tr><td>&quot;000001&quot;</td><td>2023-01-06 00:00:00</td><td>6.589011</td></tr><tr><td>&quot;000001&quot;</td><td>2023-01-09 00:00:00</td><td>6.511493</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;163415&quot;</td><td>2024-11-11 00:00:00</td><td>6.114847</td></tr><tr><td>&quot;163415&quot;</td><td>2024-11-12 00:00:00</td><td>6.101082</td></tr><tr><td>&quot;163415&quot;</td><td>2024-11-13 00:00:00</td><td>6.130332</td></tr><tr><td>&quot;163415&quot;</td><td>2024-11-14 00:00:00</td><td>5.97032</td></tr><tr><td>&quot;163415&quot;</td><td>2024-11-15 00:00:00</td><td>5.865366</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (912, 3)\n",
       "┌───────────────┬─────────────────────┬──────────┐\n",
       "│ TICKER_SYMBOL ┆ END_DATE            ┆ ADJ_NAV  │\n",
       "│ ---           ┆ ---                 ┆ ---      │\n",
       "│ str           ┆ datetime[μs]        ┆ f64      │\n",
       "╞═══════════════╪═════════════════════╪══════════╡\n",
       "│ 000001        ┆ 2023-01-03 00:00:00 ┆ 6.563172 │\n",
       "│ 000001        ┆ 2023-01-04 00:00:00 ┆ 6.530872 │\n",
       "│ 000001        ┆ 2023-01-05 00:00:00 ┆ 6.60193  │\n",
       "│ 000001        ┆ 2023-01-06 00:00:00 ┆ 6.589011 │\n",
       "│ 000001        ┆ 2023-01-09 00:00:00 ┆ 6.511493 │\n",
       "│ …             ┆ …                   ┆ …        │\n",
       "│ 163415        ┆ 2024-11-11 00:00:00 ┆ 6.114847 │\n",
       "│ 163415        ┆ 2024-11-12 00:00:00 ┆ 6.101082 │\n",
       "│ 163415        ┆ 2024-11-13 00:00:00 ┆ 6.130332 │\n",
       "│ 163415        ┆ 2024-11-14 00:00:00 ┆ 5.97032  │\n",
       "│ 163415        ┆ 2024-11-15 00:00:00 ┆ 5.865366 │\n",
       "└───────────────┴─────────────────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "df = pl.from_pandas(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    df\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import date\n",
    "\n",
    "a = pl.lit('2020-01-01') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "String(2020-01-01)"
      ],
      "text/plain": [
       "<Expr ['String(2020-01-01)'] at 0x2AE4590F7A0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cal_period_maxdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcal_period_maxdd\u001b[49m(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20240101\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20241114\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cal_period_maxdd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cal_period_maxdd(df, '20240101', '20241114')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  a.END_DATE,\n",
    "  a.TYPE_NAME,\n",
    "  a.RETURN_RATE - b.ChangePCT \n",
    "FROM\n",
    "  fund_derivatives_inner_fund_ret a\n",
    "  JOIN jy_indexquote b ON a.END_DATE = b.TradingDay \n",
    "WHERE\n",
    "  1 = 1 \n",
    "  AND a.TYPE_NAME = '主动权益-指数增强-中证500' \n",
    "  AND b.SecuCode = '000905'\n",
    "\"\"\"\n",
    "df = duckdb_query(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = duckdb.sql(\n",
    "    \"SELECT * FROM read_json('d:/config/db_config.json', records='false')\"\n",
    ")\n",
    "b = a.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_utils.db_conn import DB_CONN_JJTG_DATA\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def query_fund_alpha(trade_dt: str) -> pl.DataFrame:\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT\n",
    "        END_DATE,\n",
    "        TICKER_SYMBOL,\n",
    "        `LEVEL`,\n",
    "        INDICATOR,\n",
    "        3M,\n",
    "        6M,\n",
    "        1Y,\n",
    "        2Y,\n",
    "        3Y\n",
    "    FROM\n",
    "        fund_derivatives_fund_alpha_performance \n",
    "    WHERE\n",
    "        1 = 1 \n",
    "        AND END_DATE = '{trade_dt}' \n",
    "    \"\"\"\n",
    "    df = DB_CONN_JJTG_DATA.exec_query(query_sql)\n",
    "    df = pl.from_pandas(df)  # Convert Pandas DataFrame to Polars DataFrame\n",
    "    df = df.unpivot(\n",
    "        index=[\"END_DATE\", \"TICKER_SYMBOL\", \"LEVEL\", \"INDICATOR\"],\n",
    "        on=[\"3M\", \"6M\", \"1Y\", \"2Y\", \"3Y\"],\n",
    "        value_name=\"VALUE\",\n",
    "        variable_name=\"PERIOD\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def query_fund_type(trade_dt: str) -> pl.DataFrame:\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT\n",
    "        TICKER_SYMBOL,\n",
    "        LEVEL_1,\n",
    "        LEVEL_2,\n",
    "        LEVEL_3\n",
    "    FROM\n",
    "        fund_type_own_temp \n",
    "    WHERE\n",
    "        1 = 1 \n",
    "        AND REPORT_DATE = (\n",
    "        SELECT\n",
    "            max( REPORT_DATE ) \n",
    "        FROM\n",
    "            fund_type_own_temp \n",
    "        WHERE\n",
    "            PUBLISH_DATE <= '{trade_dt}'\n",
    "    )\n",
    "    \"\"\"\n",
    "    df = DB_CONN_JJTG_DATA.exec_query(query_sql)\n",
    "    df = pl.from_pandas(df)  # Convert Pandas DataFrame to Polars DataFrame\n",
    "    \n",
    "    # 检查列是否存在\n",
    "    if \"TICKER_SYMBOL\" not in df.columns or \"LEVEL_1\" not in df.columns or \"LEVEL_2\" not in df.columns or \"LEVEL_3\" not in df.columns:\n",
    "        raise ValueError(\"Required columns not found in the DataFrame.\")\n",
    "    \n",
    "    df = df.unpivot(\n",
    "        index=[\"TICKER_SYMBOL\"],\n",
    "        on=[\"LEVEL_1\", \"LEVEL_2\", \"LEVEL_3\"],\n",
    "        value_name=\"LEVEL_NAME\",\n",
    "        variable_name=\"LEVEL\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def query_fund_alpha_rank(trade_dt: str) -> pl.DataFrame:\n",
    "    alpha_perf = query_fund_type(trade_dt).join(\n",
    "        query_fund_alpha(trade_dt), \n",
    "        on=[\"TICKER_SYMBOL\", \"LEVEL\"]\n",
    "    )\n",
    "    \n",
    "    # Calculate rank\n",
    "    alpha_perf = alpha_perf.with_columns(\n",
    "        pl.col(\"VALUE\")\n",
    "        .over([\"LEVEL\", \"LEVEL_NAME\", \"INDICATOR\", \"PERIOD\"])\n",
    "        .rank(method=\"min\", descending=True)\n",
    "        .alias(\"VALUE_RANK\")\n",
    "    )\n",
    "    \n",
    "    # Calculate percentage rank\n",
    "    alpha_perf = alpha_perf.with_columns(\n",
    "        (\n",
    "            (pl.col(\"VALUE_RANK\")-1) / (pl.col(\"VALUE_RANK\").max()-1)\n",
    "            .over([\"LEVEL\", \"LEVEL_NAME\", \"INDICATOR\", \"PERIOD\"])\n",
    "        )\n",
    "        .alias(\"VALUE\")\n",
    "    )\n",
    "    \n",
    "    # Adjust VALUE for specific indicators\n",
    "    condition = pl.col(\"INDICATOR\").is_in([\"MAXDD\", \"ANNUAL_VOL\"])\n",
    "    alpha_perf = alpha_perf.with_columns(\n",
    "        pl.when(condition)\n",
    "        .then(1 - pl.col(\"VALUE\"))\n",
    "        .otherwise(pl.col(\"VALUE\"))\n",
    "        .alias(\"VALUE\")\n",
    "    )\n",
    "    \n",
    "    # Fill null values\n",
    "    alpha_perf = alpha_perf.with_columns(\n",
    "        pl.col(\"VALUE\").fill_null(0.5)\n",
    "    )\n",
    "    \n",
    "    return alpha_perf\n",
    "\n",
    "def query_fund_alpha_score(trade_dt: str) -> pl.DataFrame:\n",
    "    alpha_perf_rank = query_fund_alpha_rank(trade_dt)\n",
    "    indicator_weight = {\n",
    "        \"CUM_ALPHA\": 0.35,\n",
    "        \"IR\": 0.35,\n",
    "        \"MAXDD\": 0.3,\n",
    "        \"ANNUAL_VOL\": 0.0,\n",
    "    }\n",
    "    period_weight = {\n",
    "        \"3M\": 0.2,\n",
    "        \"6M\": 0.2,\n",
    "        '1Y': 0.2,\n",
    "        '2Y': 0.2,\n",
    "        '3Y': 0.2,\n",
    "    }\n",
    "    \n",
    "    # Initialize INDICATOR_WEIGHT and PERIOD_WEIGHT columns\n",
    "    alpha_perf_rank = alpha_perf_rank.with_columns(\n",
    "        pl.lit(0.0).alias(\"INDICATOR_WEIGHT\"),\n",
    "        pl.lit(0.0).alias(\"PERIOD_WEIGHT\")\n",
    "    )\n",
    "    \n",
    "    # Apply indicator weights\n",
    "    for indicator, weight in indicator_weight.items():\n",
    "        alpha_perf_rank = alpha_perf_rank.with_columns(\n",
    "            pl.when(pl.col(\"INDICATOR\") == indicator)\n",
    "            .then(weight)\n",
    "            .otherwise(pl.col(\"INDICATOR_WEIGHT\"))\n",
    "            .alias(\"INDICATOR_WEIGHT\")\n",
    "        )\n",
    "    \n",
    "    # Apply period weights\n",
    "    for period, weight in period_weight.items():\n",
    "        alpha_perf_rank = alpha_perf_rank.with_columns(\n",
    "            pl.when(pl.col(\"PERIOD\") == period)\n",
    "            .then(weight)\n",
    "            .otherwise(pl.col(\"PERIOD_WEIGHT\"))\n",
    "            .alias(\"PERIOD_WEIGHT\")\n",
    "        )\n",
    "    \n",
    "    # Calculate weighted value\n",
    "    alpha_perf_rank = alpha_perf_rank.with_columns(\n",
    "        pl.col(\"VALUE\") * pl.col(\"INDICATOR_WEIGHT\") * pl.col(\"PERIOD_WEIGHT\")\n",
    "    )\n",
    "    # Aggregate by TICKER_SYMBOL, LEVEL, LEVEL_NAME\n",
    "    alpha_perf_score = (\n",
    "        alpha_perf_rank\n",
    "        .group_by([\"TICKER_SYMBOL\", \"LEVEL\", \"LEVEL_NAME\"])\n",
    "        .agg(pl.col(\"VALUE\").sum().alias(\"VALUE\"))\n",
    "        .with_columns(pl.col(\"VALUE\").fill_null(np.nan))\n",
    "    )\n",
    "    \n",
    "    return alpha_perf_score\n",
    "\n",
    "def query_fund_alpha_score_rank(trade_dt: str) -> pl.DataFrame:\n",
    "    alpha_perf_score = query_fund_alpha_score(trade_dt)\n",
    "    \n",
    "    # Calculate rank\n",
    "    alpha_perf_score = alpha_perf_score.with_columns(\n",
    "        pl.col(\"VALUE\")\n",
    "        .over([\"LEVEL\", \"LEVEL_NAME\"])\n",
    "        .rank(method=\"min\", descending=True)\n",
    "        .alias(\"RANK\")\n",
    "    )\n",
    "    \n",
    "    # Calculate percentage rank\n",
    "    alpha_perf_score = alpha_perf_score.with_columns(\n",
    "        (pl.col(\"RANK\") / pl.col(\"RANK\").max().over([\"LEVEL\", \"LEVEL_NAME\"]))\n",
    "        .alias(\"RANK\")\n",
    "    )\n",
    "    \n",
    "    # Multiply rank by 100\n",
    "    alpha_perf_score = alpha_perf_score.with_columns(\n",
    "        pl.col(\"RANK\") * 100\n",
    "    )\n",
    "    \n",
    "    return alpha_perf_score\n",
    "\n",
    "df = query_fund_alpha_score_rank(\"20241114\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import numpy as np\n",
    "ftr_path = \"F:/data_ftr/fund_nav/\"\n",
    "ftr_list = os.listdir(ftr_path)\n",
    "parquet_path = \"F:/data_parquet/fund_nav/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fund_nav_by_parquet(\n",
    "        start_date: str, \n",
    "        end_date: str,\n",
    "        parquet_path: str = \"F:/data_parquet/fund_nav/\"\n",
    ") -> pl.DataFrame:\n",
    "    start_date = parse(start_date).strftime(\"%Y-%m-%d\")\n",
    "    end_date = parse(end_date).strftime(\"%Y-%m-%d\")\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            END_DATE, \n",
    "            TICKER_SYMBOL, \n",
    "            ADJ_NAV\n",
    "        FROM \n",
    "            '{parquet_path}*.parquet' \n",
    "        where \n",
    "            1=1\n",
    "            and END_DATE between '{start_date}' and '{end_date}'\n",
    "        order by\n",
    "            END_DATE,\n",
    "            TICKER_SYMBOL\n",
    "    \"\"\"\n",
    "    with duckdb.connect() as con:\n",
    "        df = con.sql(query).pl()\n",
    "    return df\n",
    "\n",
    "def get_trade_cal_by_parquet(\n",
    "        parquet_path: str = \"F:/data_parquet/\"\n",
    ") -> pl.DataFrame:\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            '{parquet_path}trade_cal.parquet'\n",
    "    \"\"\"\n",
    "    with duckdb.connect() as con:\n",
    "        df = con.sql(query).pl()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_fund_nav(df:pl.DataFrame, start_date:str, end_date:str):\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = parse(start_date)\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = parse(end_date)\n",
    "\n",
    "    df_filtered = (\n",
    "        df.lazy()\n",
    "        .filter(pl.col(\"END_DATE\").is_between(start_date, end_date))\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"END_DATE\").min().over(\"TICKER_SYMBOL\").alias(\"START_DATE\"),\n",
    "                pl.col(\"END_DATE\").max().over(\"TICKER_SYMBOL\").alias(\"MAX_DATE\"),\n",
    "            ]\n",
    "        )\n",
    "        .filter(\n",
    "            (pl.col(\"START_DATE\") == start_date)&(pl.col(\"MAX_DATE\") == end_date)\n",
    "        )\n",
    "    ).collect()\n",
    "    # 寻找开始之后的第一个日期\n",
    "    trade_cal = (\n",
    "        get_trade_cal_by_parquet().filter(\n",
    "            (pl.col(\"PREV_TRADE_DATE\") == start_date)\n",
    "            &(pl.col(\"IF_TRADING_DAY\") == 1)\n",
    "        ).select(\n",
    "            pl.col(\"PREV_TRADE_DATE\").alias(\"START_DATE\"),\n",
    "            pl.col(\"TRADE_DT\").alias(\"OPERATE_DATE\"),\n",
    "        )\n",
    "    )\n",
    "    df_filtered = df_filtered.join(trade_cal, on=\"START_DATE\", how=\"left\")\n",
    "    df_filtered = (\n",
    "        df_filtered.lazy()\n",
    "        .select(\n",
    "            [\n",
    "                pl.all().exclude([\"OPERATE_DATE\", \"MAX_DATE\"]),\n",
    "                ((pl.col(\"END_DATE\") - pl.col(\"OPERATE_DATE\")).dt.total_seconds() / (60 * 60 * 24) + 1).alias(\"OPERATION_DAYS\")\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"OPERATION_DAYS\") < 0).then(0).otherwise(pl.col(\"OPERATION_DAYS\")).alias(\"OPERATION_DAYS\")\n",
    "        )\n",
    "\n",
    "    ).collect()\n",
    "    return df_filtered\n",
    "\n",
    "def prepare_dates(start_date, end_date):\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = parse(start_date)\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = parse(end_date)\n",
    "    return start_date, end_date\n",
    "\n",
    "\n",
    "def cal_period_drawdown(df:pl.DataFrame, start_date:str, end_date:str):\n",
    "\n",
    "    start_date, end_date = prepare_dates(start_date, end_date)\n",
    "    \n",
    "    # df_filtered = filter_fund_nav(df, start_date, end_date)\n",
    "    temp_df = (\n",
    "        df.lazy()\n",
    "        # 计算累计最大值\n",
    "        .with_columns(\n",
    "            [\n",
    "                (100*(1 - pl.col(\"ADJ_NAV\") / _cal_cum_max(col_name=\"ADJ_NAV\", over_by=\"TICKER_SYMBOL\", order_by=\"END_DATE\"))).alias(\"drawdown\")\n",
    "            ]\n",
    "        )\n",
    "        # 计算滚动最大回撤\n",
    "        .select(\n",
    "            [\n",
    "                pl.col(\"TICKER_SYMBOL\"),\n",
    "                pl.col(\"START_DATE\"),\n",
    "                pl.col(\"END_DATE\"),\n",
    "                pl.col(\"drawdown\"),\n",
    "                _cal_cum_max(\n",
    "                    col_name=\"drawdown\", \n",
    "                    over_by=\"TICKER_SYMBOL\", \n",
    "                    order_by=\"END_DATE\"\n",
    "                ).alias(\"MAX_DRAWDOWN\"),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return temp_df.collect()\n",
    "\n",
    "def cal_period_maxdrawdown(drawdown_df:pl.DataFrame, start_date:str, end_date:str):\n",
    "    start_date, end_date = prepare_dates(start_date, end_date)\n",
    "    return (\n",
    "        drawdown_df\n",
    "        .filter(pl.col(\"END_DATE\") == end_date)\n",
    "        .select(\n",
    "            [\n",
    "                pl.col(\"TICKER_SYMBOL\"), \n",
    "                pl.col(\"START_DATE\"),\n",
    "                pl.col(\"END_DATE\"),\n",
    "                pl.col(\"MAX_DRAWDOWN\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "def cal_period_maxdd_date_and_recover(drawdown_df:pl.DataFrame):\n",
    "    dd_date = (\n",
    "        # 筛选回撤等于最大回撤的日期并且最大回撤不为0\n",
    "        drawdown_df.filter(\n",
    "            (pl.col('drawdown') == pl.col('MAX_DRAWDOWN'))\n",
    "            & (pl.col('MAX_DRAWDOWN') != 0)\n",
    "        )\n",
    "        # 只保留最大回撤日期\n",
    "        .select(\n",
    "            pl.col('TICKER_SYMBOL'),\n",
    "            pl.col('END_DATE').alias('MAXDD_DATE'),\n",
    "            pl.col('END_DATE')\n",
    "            .max()\n",
    "            .over('TICKER_SYMBOL')\n",
    "            .alias('MAX_DATE_TEMP'),\n",
    "        )\n",
    "        .filter(pl.col('MAX_DATE_TEMP') == pl.col('MAXDD_DATE'))\n",
    "        .select(pl.col('TICKER_SYMBOL'), pl.col('MAXDD_DATE'))\n",
    "    )\n",
    "    dd_recover = (\n",
    "        # 回撤与回撤修复并表\n",
    "        drawdown_df.join(dd_date, on=['TICKER_SYMBOL'], how='left')\n",
    "        # 筛选大于最大回撤日期并且当前回撤为0的日期\n",
    "        .filter(\n",
    "            (pl.col(\"END_DATE\") >= pl.col(\"MAXDD_DATE\"))\n",
    "            &(pl.col(\"drawdown\") ==0)\n",
    "        )\n",
    "        # 计算回撤为0的日期中最小的回撤修复日期\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col('END_DATE').min().over('TICKER_SYMBOL').alias('MIN_DD_RECOVERY_DATE')\n",
    "            ]\n",
    "        )\n",
    "        # 筛选出最小的回撤修复日期\n",
    "        .filter(\n",
    "            (pl.col(\"END_DATE\") == pl.col(\"MIN_DD_RECOVERY_DATE\"))\n",
    "        )\n",
    "        # 计算最大回撤修复天数\n",
    "        .select(\n",
    "            pl.col(\"TICKER_SYMBOL\"),\n",
    "            pl.col('MIN_DD_RECOVERY_DATE').alias('RECOVER_DATE'),\n",
    "            ((pl.col('MIN_DD_RECOVERY_DATE') - pl.col('MAXDD_DATE')).dt.total_seconds() / (60 * 60 * 24)).alias('MAXDD_RECOVER'),\n",
    "        )\n",
    "    )\n",
    "    return dd_date.join(dd_recover, on=['TICKER_SYMBOL'], how='left').fill_null(99999)\n",
    "\n",
    "def _cal_cum_max(\n",
    "        col_name:str = \"ADJ_NAV\", \n",
    "        over_by:str = \"TICKER_SYMBOL\", \n",
    "        order_by:str = \"END_DATE\"\n",
    "    ):\n",
    "    return pl.col(col_name).cum_max().over(over_by, order_by=pl.col(order_by))\n",
    "def _cal_ret(\n",
    "    col_name:str = \"AJD_NAV\",\n",
    "    over_by:str = \"TICKER_SYMBOL\",\n",
    "    order_by:str = \"END_DATE\"\n",
    "):\n",
    "    return (\n",
    "        (pl.col(col_name).last() / pl.col(col_name).first() - 1)*100\n",
    "    ).over(over_by, order_by=pl.col(order_by)).alias(\"CUM_RETURN\")\n",
    "\n",
    "def _cal_daily_return(\n",
    "    col_name:str = \"AJD_NAV\",\n",
    "    over_by:str = \"TICKER_SYMBOL\",\n",
    "    order_by:str = \"END_DATE\"\n",
    "):\n",
    "    return (\n",
    "        pl.col(col_name)/pl.col(col_name).shift(1) - 1 \n",
    "    ).over(over_by, order_by=pl.col(order_by)).alias(\"DAILY_RETURN\")\n",
    "\n",
    "def _cal_vol(\n",
    "    col_name:str = \"DAILY_RETURN\",\n",
    "    over_by:str = \"TICKER_SYMBOL\",\n",
    "    order_by:str = \"END_DATE\"\n",
    "):\n",
    "    return pl.col(col_name).std().over(over_by, order_by=pl.col(order_by)).alias(\"VOLATILITY\")\n",
    "def _cal_cal_period_ret_and_vol(df:pl.DataFrame, start_date:str, end_date:str):\n",
    "    start_date, end_date = prepare_dates(start_date, end_date)\n",
    "\n",
    "    return (\n",
    "        df.lazy()\n",
    "        # 计算每日收益率和累计收益率\n",
    "        .with_columns(\n",
    "            [_cal_daily_return(col_name=\"ADJ_NAV\").alias(\"DAILY_RETURN\")]\n",
    "        )\n",
    "        # 计算累计收益率和波动率\n",
    "        .with_columns(\n",
    "            [\n",
    "                _cal_vol(col_name=\"DAILY_RETURN\").alias(\"VOLATILITY\"),\n",
    "                _cal_ret(col_name=\"ADJ_NAV\").alias(\"CUM_RETURN\"),\n",
    "            ]\n",
    "        ).filter(pl.col(\"END_DATE\") == end_date)\n",
    "    ).collect()\n",
    "\n",
    "def _cal_annual_return_and_vol(df:pl.DataFrame):\n",
    "    return (\n",
    "        df.select(\n",
    "                [\n",
    "                    pl.col(\"TICKER_SYMBOL\"),\n",
    "                    pl.col(\"START_DATE\"),\n",
    "                    pl.col(\"END_DATE\"),\n",
    "                    pl.col(\"CUM_RETURN\"),\n",
    "                    (((pl.col(\"CUM_RETURN\")/100 + 1)**(365/pl.col(\"OPERATION_DAYS\")) - 1)*100).alias(\"ANNUAL_RETURN\"),\n",
    "                    pl.col(\"VOLATILITY\"),\n",
    "                    (pl.col(\"VOLATILITY\")*np.sqrt(252)*100).alias(\"ANNUAL_VOLATILITY\")\n",
    "                ]\n",
    "            )\n",
    "    )\n",
    "def cal_period_ret_and_vol(df:pl.DataFrame, start_date:str, end_date:str):\n",
    "    start_date, end_date = prepare_dates(start_date, end_date)\n",
    "    result = (\n",
    "            _cal_cal_period_ret_and_vol(df, start_date, end_date)\n",
    "            .filter(pl.col(\"END_DATE\") == end_date)\n",
    "    )\n",
    "    return _cal_annual_return_and_vol(result)\n",
    "\n",
    "def cal_period_perform(df:pl.DataFrame, start_date:str, end_date:str):\n",
    "    start_date, end_date = prepare_dates(start_date, end_date)\n",
    "    df_filtered = filter_fund_nav(df, start_date, end_date)\n",
    "    temp_df = cal_period_ret_and_vol(df_filtered, start_date, end_date)\n",
    "    dd = cal_period_drawdown(df_filtered, start_date, end_date)\n",
    "    dd_date_recover = cal_period_maxdd_date_and_recover(dd)\n",
    "    maxdd = cal_period_maxdrawdown(dd, '20221230', '20241114')\n",
    "    maxdd = maxdd.join(dd_date_recover, on=['TICKER_SYMBOL'], how='left')\n",
    "    temp_df = (\n",
    "        temp_df\n",
    "        .join(maxdd, on=['TICKER_SYMBOL', \"START_DATE\", \"END_DATE\"], how='left')\n",
    "        .with_columns(\n",
    "            [\n",
    "                (pl.col(\"CUM_RETURN\")/pl.col(\"VOLATILITY\")/100).alias(\"SHARP_RATIO\"),\n",
    "                (pl.col(\"ANNUAL_RETURN\")/pl.col(\"ANNUAL_VOLATILITY\")).alias(\"SHARP_RATIO_ANNUAL\"),\n",
    "                (pl.col(\"ANNUAL_RETURN\")/pl.col(\"MAX_DRAWDOWN\")).alias(\"CALMAR_RATIO_ANNUAL\"),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_fund_nav_by_parquet('20231228', '20241114')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_970_699, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>END_DATE</th><th>TICKER_SYMBOL</th><th>ADJ_NAV</th><th>START_DATE</th><th>OPERATION_DAYS</th></tr><tr><td>date</td><td>str</td><td>f64</td><td>date</td><td>f64</td></tr></thead><tbody><tr><td>2023-12-29</td><td>&quot;000001&quot;</td><td>5.05424</td><td>2023-12-29</td><td>0.0</td></tr><tr><td>2023-12-29</td><td>&quot;000003&quot;</td><td>0.944113</td><td>2023-12-29</td><td>0.0</td></tr><tr><td>2023-12-29</td><td>&quot;000004&quot;</td><td>0.928828</td><td>2023-12-29</td><td>0.0</td></tr><tr><td>2023-12-29</td><td>&quot;000005&quot;</td><td>1.613538</td><td>2023-12-29</td><td>0.0</td></tr><tr><td>2023-12-29</td><td>&quot;000006&quot;</td><td>2.387004</td><td>2023-12-29</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2024-11-14</td><td>&quot;970210&quot;</td><td>1.0285</td><td>2023-12-29</td><td>318.0</td></tr><tr><td>2024-11-14</td><td>&quot;970211&quot;</td><td>1.1124</td><td>2023-12-29</td><td>318.0</td></tr><tr><td>2024-11-14</td><td>&quot;970212&quot;</td><td>1.1094</td><td>2023-12-29</td><td>318.0</td></tr><tr><td>2024-11-14</td><td>&quot;970213&quot;</td><td>1.1047</td><td>2023-12-29</td><td>318.0</td></tr><tr><td>2024-11-14</td><td>&quot;970214&quot;</td><td>1.1021</td><td>2023-12-29</td><td>318.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_970_699, 5)\n",
       "┌────────────┬───────────────┬──────────┬────────────┬────────────────┐\n",
       "│ END_DATE   ┆ TICKER_SYMBOL ┆ ADJ_NAV  ┆ START_DATE ┆ OPERATION_DAYS │\n",
       "│ ---        ┆ ---           ┆ ---      ┆ ---        ┆ ---            │\n",
       "│ date       ┆ str           ┆ f64      ┆ date       ┆ f64            │\n",
       "╞════════════╪═══════════════╪══════════╪════════════╪════════════════╡\n",
       "│ 2023-12-29 ┆ 000001        ┆ 5.05424  ┆ 2023-12-29 ┆ 0.0            │\n",
       "│ 2023-12-29 ┆ 000003        ┆ 0.944113 ┆ 2023-12-29 ┆ 0.0            │\n",
       "│ 2023-12-29 ┆ 000004        ┆ 0.928828 ┆ 2023-12-29 ┆ 0.0            │\n",
       "│ 2023-12-29 ┆ 000005        ┆ 1.613538 ┆ 2023-12-29 ┆ 0.0            │\n",
       "│ 2023-12-29 ┆ 000006        ┆ 2.387004 ┆ 2023-12-29 ┆ 0.0            │\n",
       "│ …          ┆ …             ┆ …        ┆ …          ┆ …              │\n",
       "│ 2024-11-14 ┆ 970210        ┆ 1.0285   ┆ 2023-12-29 ┆ 318.0          │\n",
       "│ 2024-11-14 ┆ 970211        ┆ 1.1124   ┆ 2023-12-29 ┆ 318.0          │\n",
       "│ 2024-11-14 ┆ 970212        ┆ 1.1094   ┆ 2023-12-29 ┆ 318.0          │\n",
       "│ 2024-11-14 ┆ 970213        ┆ 1.1047   ┆ 2023-12-29 ┆ 318.0          │\n",
       "│ 2024-11-14 ┆ 970214        ┆ 1.1021   ┆ 2023-12-29 ┆ 318.0          │\n",
       "└────────────┴───────────────┴──────────┴────────────┴────────────────┘"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_fund_nav(df, '20231229', '20241114')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant_utils.db_conn import DB_CONN_JJTG_DATA\n",
    "import pandas as pd\n",
    "def get_needed_dates_df(end_date: str = None, start_date: str = None) -> pd.DataFrame:\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT\n",
    "        date_format(START_DATE,'%Y%m%d') as START_DATE,\n",
    "        date_format(END_DATE,'%Y%m%d') as END_DATE,\n",
    "        DATE_NAME\n",
    "    FROM\n",
    "        `portfolio_dates`\n",
    "    WHERE\n",
    "        1=1\n",
    "        and (END_DATE BETWEEN '{start_date}' AND '{end_date}')\n",
    "    \"\"\"\n",
    "    return DB_CONN_JJTG_DATA.exec_query(query_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from dateutil.parser import parse\n",
    "from quant_pl.performance_pl import PerformancePL\n",
    "from quant_utils.db_conn import DB_CONN_JJTG_DATA\n",
    "import pandas as pd\n",
    "def get_nav(end_date):\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT\n",
    "        DATE_FORMAT( TRADE_DT, \"%Y%m%d\" ) AS END_DATE,\n",
    "        a.PORTFOLIO_NAME AS TICKER_SYMBOL,\n",
    "        PORTFOLIO_NAV AS NAV \n",
    "    FROM\n",
    "        portfolio_nav a\n",
    "        JOIN portfolio_info b ON a.PORTFOLIO_NAME = b.PORTFOLIO_NAME \n",
    "    WHERE\n",
    "        1 = 1 \n",
    "        AND a.TRADE_DT >= b.LISTED_DATE\n",
    "        AND a.TRADE_DT <= '{end_date}'\n",
    "    \"\"\"\n",
    "    return DB_CONN_JJTG_DATA.exec_query(query_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_nav(\"20241120\")\n",
    "df = pl.from_pandas(df).with_columns(pl.col(\"END_DATE\").str.strptime(pl.Datetime, \"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>TICKER_SYMBOL</th><th>START_DATE</th><th>END_DATE</th><th>CUM_RETURN</th><th>ANNUAL_RETURN</th><th>VOLATILITY</th><th>ANNUAL_VOLATILITY</th><th>SHARP_RATIO</th><th>SHARP_RATIO_ANNUAL</th><th>MAXDD</th><th>CALMAR_RATIO_ANNUAL</th><th>MAXDD_DATE</th><th>MAXDD_RECOVER</th><th>RECOVER_DATE</th></tr><tr><td>str</td><td>datetime[μs]</td><td>datetime[μs]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>datetime[μs]</td><td>f64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;知己优选-均衡小确幸&quot;</td><td>2021-09-03 00:00:00</td><td>2024-11-20 00:00:00</td><td>-2.505698</td><td>-0.787187</td><td>0.55475</td><td>8.806385</td><td>-4.516804</td><td>-0.089388</td><td>17.159819</td><td>-0.045874</td><td>2024-02-05 00:00:00</td><td>99999.0</td><td>null</td></tr><tr><td>&quot;知己优选-进取全明星&quot;</td><td>2021-09-03 00:00:00</td><td>2024-11-20 00:00:00</td><td>-19.755698</td><td>-6.624834</td><td>1.037303</td><td>16.466672</td><td>-19.045257</td><td>-0.402318</td><td>39.573375</td><td>-0.167406</td><td>2024-02-05 00:00:00</td><td>99999.0</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 14)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ TICKER_SY ┆ START_DAT ┆ END_DATE  ┆ CUM_RETUR ┆ … ┆ CALMAR_RA ┆ MAXDD_DAT ┆ MAXDD_REC ┆ RECOVER_ │\n",
       "│ MBOL      ┆ E         ┆ ---       ┆ N         ┆   ┆ TIO_ANNUA ┆ E         ┆ OVER      ┆ DATE     │\n",
       "│ ---       ┆ ---       ┆ datetime[ ┆ ---       ┆   ┆ L         ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ datetime[ ┆ μs]       ┆ f64       ┆   ┆ ---       ┆ datetime[ ┆ f64       ┆ datetime │\n",
       "│           ┆ μs]       ┆           ┆           ┆   ┆ f64       ┆ μs]       ┆           ┆ [μs]     │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 知己优选- ┆ 2021-09-0 ┆ 2024-11-2 ┆ -2.505698 ┆ … ┆ -0.045874 ┆ 2024-02-0 ┆ 99999.0   ┆ null     │\n",
       "│ 均衡小确  ┆ 3         ┆ 0         ┆           ┆   ┆           ┆ 5         ┆           ┆          │\n",
       "│ 幸        ┆ 00:00:00  ┆ 00:00:00  ┆           ┆   ┆           ┆ 00:00:00  ┆           ┆          │\n",
       "│ 知己优选- ┆ 2021-09-0 ┆ 2024-11-2 ┆ -19.75569 ┆ … ┆ -0.167406 ┆ 2024-02-0 ┆ 99999.0   ┆ null     │\n",
       "│ 进取全明  ┆ 3         ┆ 0         ┆ 8         ┆   ┆           ┆ 5         ┆           ┆          │\n",
       "│ 星        ┆ 00:00:00  ┆ 00:00:00  ┆           ┆   ┆           ┆ 00:00:00  ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '20210903'\n",
    "end_date = '20241120'\n",
    "perf = PerformancePL(df, start_date, end_date)\n",
    "perf.stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
